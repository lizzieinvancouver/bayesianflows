%% Stuff cut in October 2025 (on Halloween) ...


[ML stuff] may be especially important to understand how new techniques to ecology, such as those from machine learning \citep{pichler2023machine}, actually apply to help answer ecological questions.

In recent decades, the field of ecology has become more policy-relevant as growing anthropogenic pressures have increased the need to manage and understand ecological systems  \citep{hak2016sustainable,lindenmayer2010science}. As ecologists have worked to develop predictive models to meet these demands they have developed ever larger datasets \citep{Hampton2013}. These bigger data, however, are also messier data. Such data generally require more complex models, such as those that accommodate both the underlying biological processes and how the measurements were made. Some subdisciplines in ecology have long used these types of models \citep[generally in fields focused on inferring population sizes for management,][]{muthuku2008,zheng2007,trijoulet2018,strinella2020potential}. Most, however, have not. This has left a number of ecologists to try to adapt what they were trained in---traditional statistical methods (e.g. $F$ and $t$ tests) and a strong focus on null hypothesis testing---to increasingly complex datasets. 
% Often they have done this by fitting multi-way interaction terms, using random effects to correct for group level factors, or comparing across a large suite of models. 
% Often they have done this by fitting multi-way interaction terms (rather than using mechanistic models informed by biological understanding), using random effects to correct for group level factors (rather than explicit models of data-collection biases), or comparing across a large suite of models (because they cannot fit a single model that accounts for all the idiosyncrasies and biases) ... and so aim to average out the noise to leave only the signal 



%% Stuff cut in August 2024

Intro:
Multi-way interaction terms can make main effects hard to interpret and require much larger sample sizes to estimate reliably. Null hypotheses are rarely true and can lead to confusion over what is scientifically important versus `significant' \citep{gelmanhill,muff2022rewriting}. Many model comparison and machine learning approaches prefer models whose inferences match the idiosyncrasies and biases in the available data, but don’t generalize.  The disconnect between the traditional statistical tools available in ecology and the field's fundamental theory is being made ever-clearer as the need for robust ecological forecasts grows. 

Feedbacks section:
This process more fully integrates mathematical modeling into statistical modeling. To complete Steps 1-2, you have to understand the underlying math of your model enough to simulate data from it. This can be challenging at first (e.g. recalling how to simulate $y$ data for a simple linear regression is not straightforward when you rarely do it), but is immensely beneficial to forcing you to understand your model and its consequences. Indeed, we have found the greatest insights come not from the step we all know best---fitting the model with empirical data (Step 3)---but from every other step in this workflow. % Further, it exploits many of the benefits of Bayesian approaches, while systematically avoiding major pitfalls. 
% Developing simulated data to test the model, running prior and retrodictive checks all dive you deep into understanding your statistical model, which suddenly you may find yourself thinking through much more mechanistically. In our experience this process has quickly translated into insights for our biological systems, and changed how we approach statistical models. 
% MB: I wonder if it's beneficial to frame this more as "dive deep into connecting your statistical model to your domain expertise"?  I often find myself trying to emphasize that people already have the domain expertise but they're not incorporating it into their analyses.  A lot of what this workflow is trying to do is facilitate that integration to leverage _what the analysts have always had!

 \subsection*{Thinking about priors} 
This workflow also can quickly ease the common concern of those unfamiliar with Bayesian approaches: priors. Often treated as the big bad wolf of Bayesian, or the unseen hand producing biased model fits, according to some. In reality, how much priors influence your model fit is up to your model and your data. Depending on those two parts, the likelihood (influenced by your data) can easily overwhelm your priors (Fig. \ref{fig:misspecifyprior}). Indeed, most work on the dangers of priors and `prior misspecification'  focuses on cases where you have very little data for the model you're trying to fit. Priors, however, can only matter more than you know when you fail to think through and check them---that is, you skip Steps 1-2. 

% They show up as half of the equation that gives you your model posterior, and philosophically, Bayesian was built around the idea that you have prior knowledge that you trust and want to compare to new data (with your new data showing up through your likelihood). In reality, few Bayesian analyses in ecology are approached this way. 
%JD16Aug --  Dolph always compares the 'danger' of priors in the belief that Saddam Hussein had WMDs - data was sparse, so priors overwhelmed. Han Solo flying the Millennium Falcon through an asteroid field illustrates the benefits of priors. We need to know where we are on the Saddam - Han spectrum.
% WDP: Jonathan, this is the first time I've read you making a sci-fi reference in print and I'm extremely excited by it

 \subsection*{Knowing our limits}  % Dive into the simplified complexity conundrum

We now both add complexity and simplify based on a more careful reckoning. Often our starting model is not simple.  It often includes grouping factors that may be difficult to fit, but only those grouping factors that we see as absolutely critical to the question, model and data at hand. We still add and consider additional grouping factors and interactions, but we do so with a careful idea of how stable the model given the data likely is with them, and we rarely fit complex three-way interactions or similar---unless we have carefully designed the model and data collection for that aim. % The ending model is often not as complex as we may have fit if we did not follow all the steps. 
% And---through them, especially Step 4---we can feel confident our model is capturing important variation. 

 \subsection*{Fitting bespoke models} 
Once we have identified the limits to our data, we can fit a bespoke model to estimate the parameters we are actually interested in rather than the numbers that are convenient to estimate. Models can be specifically designed to estimate and report effects in relevant units (e.g. per \degree C of warming)---always with estimated uncertainty. Such flexibility is incredibly powerful in ecology where data are often influenced by complex spatial or temporal patterns, non-linear processes are widespread, and common data types are non-Gaussian (e.g. counts, percent cover, etc.). 

Bayesian models have many benefits, but an often-mentioned one is that `you can fit any model you want.' While this is not entirely true \citep{BDA,reid2019}, Bayesian modeling options can feel limitless when compared to the models ecologists can fit in popular modeling packages (e.g. \textsf{lme4} package in \textsf{R}). As long as you can write out the likelihood of your desired model \citep[and sometimes even if you can't,][]{Sunnaaker2013} and assign priors to all parameters, you can generally `fit' the model. However, the flexibility of Bayesian models is sometimes seen as a weakness: you can fit almost whatever you want, but critical parts of your model might be almost entirely unimpacted by your data. In ecological model fitting, we're currently most often interested in parameter estimates strongly informed by our data, making this problem sound especially dangerous. In reality, however, this problem is not related to modeling, but to experimental design---and a flawed experimental design leading to low power for your model is much easier to see through using our workflow compared to using traditional null hypothesis testing methods. Low power usually becomes very obvious in Step 2 when you need to recover your parameter estimates and find you need simulated data very different (e.g. higher sample size, lower error) than your empirical data to achieve this.

% Priors
Current training often includes a very strong focus on mathematically-convenient priors, because of the importance of conjugate priors in closed form solutions for particular posteriors. Modern algorithms, such as HMC, do not require conjugate priors. 

%% Stuff cut in October/November 2023
Bayesian approaches are not new to ecology. They have long been used in certain subdisciplines related to infer population sizes of things people want to eat or manage. These are also cases where the underlying biological model was well established, and underlying data collection was especially messy. For example, wildlife biologists frequently use mark-recapture data and associated models to estimate population sizes; such methods almost always use Hidden Markov models to link from the data generating process (where all individuals are not always perfectly observed) to the population model, which can rarely be fit without Bayesian methods \citep{muthuku2008,zheng2007,strinella2020potential}. Similarly fisheries biology has tended towards more complex models---such as state-space models---to estimate stocks, which address similar issues and are similarly easiest to fit with Bayesian approaches \citep{trijoulet2018,millar2000}. % For decades, Bayesian training in ecology has focused on these aims, but as data and methods change, so has how ecologists are using Bayesian models.

Away from these fields, however, ecologists have largely focused on frequentist statistics and null hypothesis testing. Such approaches seem superficially straightforward, and centuries of effort have led to standardized ways to address many particular questions. These approaches, however, are based on rigid assumptions that often don't hold for many ecological datasets.  For example spatial, temporal and phylogenetic correlations often violate the independence assumptions inherent to these methods. % This approach can, however, mean underlying assumptions are ignored, as spatial, time-series and phylogenetic data introduce non-independencies. 
Ecologists try to address some of these challenges for larger, more complex datasets by fitting multi-way interaction terms, using random effects to correct for group level factors, or comparing a cross of suite of models. But the outcomes are not often aligned with our ultimate aims:  multi-way interaction terms can make main effects hard to interpret, null hypotheses tend to be rejected even when the underlying effect sizes are weak \citep{gelmanhill,muff2022rewriting}, and many model comparison approaches prefer models whose inferences match the idiosyncratic fluctuations in the ecological data, but don’t generalize to other observations. These practical realities highlight that our current approaches are not meeting the challenges of our data combined with our ultimate aims in ecology today.



The average ecologist today has a diversified skillset compared to an ecologist of decades ago---one that could potentially meet this challenge. Ecology has long been a field with deep statistical training, but the modern ecologist is now also expected to be computational: to handle large datasets, produce repeatable workflows, and translate models into forecasts for policy and planning. Many ecologists now bridge field, lab and computational methods. Bayesian methods can help facilitate this new job description, while also helping meet the demands for better models and forecasts. % As such, the rise of Bayesian approaches is especially timely for ecology. % The average modern ecologist is computational, but often grounded in the natural history of a particular system (err, maybe, on both these accounts, but whatever).

Today, as large-scale ecological data becomes available for more diverse systems and for questions addressing other aims, ecologists are using Bayesian models in new ways. Unfortunately, there is naturally a lag in training in statistics, and in Bayesian modeling in particular. Bayesian approaches provide a pathway to powerful models that can transform how we understand our systems, but they can also lead to pitfalls most ecologists are not trained to notice or manage. Many of these pitfalls can be avoided by approaching Bayesian analyses through specific workflows \citep{betanworkflow,vandeschoot2021}, which themselves are built on a process of how to do not just statistics, but how to do science. % Maybe address workflow comment here? 

These workflows---and the one we describe below---are focused on simulating data from models at multiple steps. This is a ground-shift from most statistical training in ecology, which has focused strongly on null hypothesis testing, but a timely one. As the modern ecologist of today is often computational, simulation methods are a more natural extension---and one that can provide insights and build intuition into both statistics and the natural systems we study. % Including simulation more consistently into how we build statistical models allows more interactive learning, easier tests of power, and builds intuition into both statistics and the natural systems we study. It can also help meet the demands on ecology for better models and forecasts. 
